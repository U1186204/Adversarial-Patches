{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10eb86e0",
   "metadata": {},
   "source": [
    "# AIPI 590 - XAI | Adversarial Patches\n",
    "\n",
    "Description: \n",
    "\n",
    "Christian Moreira"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078f4f3c",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea61488b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n",
      "Custom patch will be saved to: saved_models/tutorial10\\custom\n",
      "Looking for logo at: data\\ung_logo.png\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "from PIL import Image\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline # <-- FIX 1\n",
    "%matplotlib inline\n",
    "# from IPython.display import set_matplotlib_formats\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg', 'pdf') # <-- FIX 1\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "## Progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "\n",
    "# Torchvision\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "\n",
    "# PyTorch Lightning\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default.\n",
    "    !pip install --quiet pytorch_lightning>=1.4\n",
    "    import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "# --- Paths ---\n",
    "# Path to the folder where the datasets are/should be downloaded\n",
    "DATASET_PATH = \"data\"  # <-- CORRECTED PATH\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"saved_models/tutorial10\" # <-- CORRECTED PATH\n",
    "# Path for our custom-generated patch\n",
    "CUSTOM_PATCH_PATH = os.path.join(CHECKPOINT_PATH, \"custom\")\n",
    "os.makedirs(CUSTOM_PATCH_PATH, exist_ok=True)\n",
    "# Path to our logo\n",
    "LOGO_PATH = os.path.join(DATASET_PATH, \"ung_logo.png\") # <-- CORRECTED PATH\n",
    "\n",
    "# --- Reproducibility ---\n",
    "pl.seed_everything(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# --- Device ---\n",
    "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
    "print(\"Using device\", device)\n",
    "print(f\"Custom patch will be saved to: {CUSTOM_PATCH_PATH}\")\n",
    "print(f\"Looking for logo at: {LOGO_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fd9fdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial10/TinyImageNet.zip...\n",
      "Unzipping file...\n",
      "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial10/patches.zip...\n",
      "Unzipping file...\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "import zipfile\n",
    "\n",
    "# Github URL where the dataset is stored for this tutorial\n",
    "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial10/\"\n",
    "# Files to download\n",
    "pretrained_files = [(DATASET_PATH, \"TinyImageNet.zip\"), (CHECKPOINT_PATH, \"patches.zip\")]\n",
    "\n",
    "# Create checkpoint path if it doesn't exist yet\n",
    "os.makedirs(DATASET_PATH, exist_ok=True)\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "# For each file, check whether it already exists. If not, try downloading it.\n",
    "for dir_name, file_name in pretrained_files:\n",
    "    file_path = os.path.join(dir_name, file_name)\n",
    "    if not os.path.isfile(file_path):\n",
    "        # --- THIS LINE IS NOW FIXED ---\n",
    "        file_url = base_url + file_name\n",
    "        print(f\"Downloading {file_url}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "        except HTTPError as e:\n",
    "            print(\"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\", e)\n",
    "        if file_name.endswith(\".zip\"):\n",
    "            print(\"Unzipping file...\")\n",
    "            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                # --- THIS IS FIX 2 (for Windows) ---\n",
    "                zip_ref.extractall(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04615dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to saved_models/tutorial10\\hub\\checkpoints\\resnet34-b627a593.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83.3M/83.3M [00:02<00:00, 35.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Load CNN architecture pretrained on ImageNet\n",
    "os.environ[\"TORCH_HOME\"] = CHECKPOINT_PATH\n",
    "pretrained_model = torchvision.models.resnet34(weights='IMAGENET1K_V1')\n",
    "pretrained_model = pretrained_model.to(device)\n",
    "\n",
    "# No gradients needed for the network\n",
    "pretrained_model.eval()\n",
    "for p in pretrained_model.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ce9040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean and Std from ImageNet\n",
    "NORM_MEAN = np.array([0.485, 0.456, 0.406])\n",
    "NORM_STD = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "# No resizing and center crop necessary as images are already preprocessed.\n",
    "plain_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=NORM_MEAN,\n",
    "                         std=NORM_STD)])\n",
    "\n",
    "# Load dataset and create data loader\n",
    "imagenet_path = os.path.join(DATASET_PATH, \"TinyImageNet/\")\n",
    "assert os.path.isdir(imagenet_path), f\"Could not find the ImageNet dataset at expected path \\\"{imagenet_path}\\\". \" + \\\n",
    "                                     f\"Please make sure to have downloaded the ImageNet dataset here, or change the {DATASET_PATH=} variable.\"\n",
    "dataset = torchvision.datasets.ImageFolder(root=imagenet_path, transform=plain_transforms)\n",
    "\n",
    "# --- THIS IS FIX 3 (for Windows) ---\n",
    "data_loader = data.DataLoader(dataset, batch_size=32, shuffle=False, drop_last=False, num_workers=0)\n",
    "\n",
    "# Load label names to interpret the label numbers 0 to 999\n",
    "with open(os.path.join(imagenet_path, \"label_list.json\"), \"r\") as f:\n",
    "    label_names = json.load(f)\n",
    "\n",
    "def get_label_index(lab_str):\n",
    "    assert lab_str in label_names, f\"Label \\\"{lab_str}\\\" not found. Check the spelling of the class.\"\n",
    "    return label_names.index(lab_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6de3f8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Acquired! We will make the model see: **ashcan** (Index: 412)\n",
      "This class is also known as: 'trash can, garbage can, wastebin...'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "target_class_name = 'ashcan' \n",
    "target_class_idx = 412\n",
    "\n",
    "assert target_class_name in label_names, \"Target class name not in label list!\"\n",
    "\n",
    "print(f\"Target Acquired! We will make the model see: **{target_class_name}** (Index: {target_class_idx})\")\n",
    "print(\"This class is also known as: 'trash can, garbage can, wastebin...'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f5deb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(dataset_loader, img_func=None):\n",
    "    tp, tp_5, counter = 0., 0., 0.\n",
    "    for imgs, labels in tqdm(dataset_loader, desc=\"Validating...\"):\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        if img_func is not None:\n",
    "            imgs = img_func(imgs, labels)\n",
    "        with torch.no_grad():\n",
    "            preds = pretrained_model(imgs)\n",
    "        tp += (preds.argmax(dim=-1) == labels).sum()\n",
    "        tp_5 += (preds.topk(5, dim=-1)[1] == labels[...,None]).any(dim=-1).sum()\n",
    "        counter += preds.shape[0]\n",
    "    acc = tp.float().item()/counter\n",
    "    top5 = tp_5.float().item()/counter\n",
    "    print(f\"Top-1 error: {(100.0 * (1 - acc)):4.2f}%\")\n",
    "    print(f\"Top-5 error: {(100.0 * (1 - top5)):4.2f}%\")\n",
    "    return acc, top5\n",
    "\n",
    "def show_prediction(img, label, pred, K=5, adv_img=None, noise=None):\n",
    "    if isinstance(img, torch.Tensor):\n",
    "        img = img.cpu().permute(1, 2, 0).numpy()\n",
    "        img = (img * NORM_STD[None,None]) + NORM_MEAN[None,None]\n",
    "        img = np.clip(img, a_min=0.0, a_max=1.0)\n",
    "        label = label.item()\n",
    "    if abs(pred.sum().item() - 1.0) > 1e-4:\n",
    "        pred = torch.softmax(pred, dim=-1)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10,2), gridspec_kw={'width_ratios': [1, 1]})\n",
    "    ax[0].imshow(img)\n",
    "    ax[0].set_title(label_names[label])\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    topk_vals, topk_idx = pred.topk(K, dim=-1)\n",
    "    topk_vals, topk_idx = topk_vals.cpu().numpy(), topk_idx.cpu().numpy()\n",
    "    ax[-1].barh(np.arange(K), topk_vals*100.0, align='center', color=[\"C0\" if topk_idx[i]!=label else \"C2\" for i in range(K)])\n",
    "    ax[-1].set_yticks(np.arange(K))\n",
    "    ax[-1].set_yticklabels([label_names[c] for c in topk_idx])\n",
    "    ax[-1].invert_yaxis()\n",
    "    ax[-1].set_xlabel('Confidence')\n",
    "    ax[-1].set_title('Predictions')\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# Grab a batch of images for later testing\n",
    "exmp_batch, label_batch = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f27e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSOR_MEANS = torch.FloatTensor(NORM_MEAN).to(device)[:,None,None]\n",
    "TENSOR_STD = torch.FloatTensor(NORM_STD).to(device)[:,None,None]\n",
    "\n",
    "def patch_forward(patch):\n",
    "    # This maps the patch nn.Parameter (which is unbound) to the\n",
    "    # correct normalized image space.\n",
    "    # 1. torch.tanh(patch): -> [-1, 1]\n",
    "    # 2. (... + 1) / 2:      -> [0, 1] (pixel space)\n",
    "    # 3. (... - MEANS) / STD: -> normalized space\n",
    "    patch_0_1 = (torch.tanh(patch) + 1) / 2\n",
    "    return (patch_0_1 - TENSOR_MEANS) / TENSOR_STD\n",
    "\n",
    "def place_patch(img, patch):\n",
    "    for i in range(img.shape[0]):\n",
    "        # Randomly place patch\n",
    "        h_offset = np.random.randint(0,img.shape[2]-patch.shape[2]-1)\n",
    "        w_offset = np.random.randint(0,img.shape[3]-patch.shape[1]-1)\n",
    "        # Apply the patch\n",
    "        img[i,:,h_offset:h_offset+patch.shape[2],w_offset:w_offset+patch.shape[1]] = patch_forward(patch)\n",
    "    return img\n",
    "\n",
    "def eval_patch(model, patch, val_loader, target_class):\n",
    "    model.eval()\n",
    "    tp, tp_5, counter = 0., 0., 0.\n",
    "    with torch.no_grad():\n",
    "        for img, img_labels in tqdm(val_loader, desc=\"Validating...\", leave=False):\n",
    "            # For stability, place the patch at 4 random locations per image\n",
    "            for _ in range(4):\n",
    "                patch_img = place_patch(img.clone(), patch)\n",
    "                patch_img = patch_img.to(device)\n",
    "                img_labels = img_labels.to(device)\n",
    "                pred = model(patch_img)\n",
    "                # We count a \"success\" if the model predicts our target class\n",
    "                # AND the image was not already our target class.\n",
    "                tp += torch.logical_and(pred.argmax(dim=-1) == target_class, img_labels != target_class).sum()\n",
    "                tp_5 += torch.logical_and((pred.topk(5, dim=-1)[1] == target_class).any(dim=-1), img_labels != target_class).sum()\n",
    "                counter += (img_labels != target_class).sum()\n",
    "    \n",
    "    # Handle the case where counter is zero (e.g., if all images are the target class)\n",
    "    if counter.item() == 0:\n",
    "        return torch.tensor(0.0), torch.tensor(0.0)\n",
    "        \n",
    "    acc = tp.float() / counter\n",
    "    top5 = tp_5.float() / counter\n",
    "    return acc, top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7edf8b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded and processed logo into a torch.Size([3, 64, 64]) tensor.\n"
     ]
    },
    {
     "data": {
      "application/pdf": "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",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"280.512pt\" height=\"295.255125pt\" viewBox=\"0 0 280.512 295.255125\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2025-11-02T18:55:32.679004</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.10.6, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 295.255125 \n",
       "L 280.512 295.255125 \n",
       "L 280.512 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g clip-path=\"url(#p0c9b9db7b6)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAAAXIAAAFyCAYAAADoJFEJAAAXLUlEQVR4nO3d2ZOU133G8d63WZmNfRhWwbCITaANS2hxUCRFqkolcUWWHG+pSiWV/C25yFUubCVSIjm5kCyXZVuOrAUESJawAIEEzAzDAMMsPUvP0nt3qpPL87zUtOmG/sH3c/noVE/3TPPorXp/7zl+n89X9gEAzArc6TcAALg1FDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxFDkAGEeRA4BxoTv9BtB4/H6/zOPNHTIvl0tOlp6frvn7ultFYs1Vrc9l5uv2XmATV+QAYBxFDgDGUeQAYBxFDgDGcbPzHhaOxGXesXKTzLtXb5H5bPKak129cFKuLZfLvntZMBR2stWb9sm10XiLzMdHzsl8dmJE5sVivqr3CHu4IgcA4yhyADCOIgcA4yhyADCOIgcA45haucsEAkEna+lYKdcu790u8y339cv80Yf2yPztd37tZDcun5Zr89lFX3Xc7QL8AX394fd75R4v7TFAUxJbDpRLpepexENr5xon273nAbl2966tMn//o1UyHx78WubjI185WXpuSq6916eKrOKKHACMo8gBwDiKHACMo8gBwDiKHACMY2rFqGi8VeY9a7c52eo+Pf3w5OMPy/yppw7LPJLQP/PSoLvHx9enj1d1KEKiRR9aERU/MxJtkmuDoUhVB2WUPSZOivnckt+31wEa2fSczNds2OVkL75wRK5dv9VdW/HAA3tl/vY7v5H5yc9WONno8Hm5Nnn9oswL+YzM0Ri4IgcA4yhyADCOIgcA4yhyADCOIgcA45haMapjxQaZ37//ESf7/st/LtcuW6lfYzhZkHloUec7d7p7s3z6+/1ybTQWlXlPd5fMl/d0OllXR5tc29Ksp1nCYfdUnopisSjz2ZQ7oTI+kZRrr41OyDyZ1HuZPHhgt5N1994n1567qvelaY33yPylV16W+b7d7p46r/7nW3JtZnGmqtOH0Bi4IgcA4yhyADCOIgcA4yhyADCOIgcA45haMWp+dlzm7S0JJ2vrWSfXXriRlbnXITHBgN6zZPN97l4uP3xFT8ps2rRR5u0demqlHIo5Wa6orz/yRf3GSx6fx+vkoEjQ/Q+RoD4hqJxbkPnY6HWZt4nPeXWuXNXfYdZjemgxqz9Q38bNThb06dfIzOupFTQ2rsgBwDiKHACMo8gBwDiKHACM42anUek5/cj4ufPnnGwmOSbXBgP6BmPB46Zh0eOuYS7U7mT37X9crp1M5WV+bUw/Ll8sNfaBBuGg/ifU0qa3P5gUHz+T07+TakXD+rrs4sVLTnblsptV5DL65i0aG1fkAGAcRQ4AxlHkAGAcRQ4AxlHkAGAcUytGFQt60mFyfNTJLl24INeu27Vc5jML+vFtL6PT+lH/e4HXtgBTc7WZRKlGa0w/on/srDvJlE27h2fcdN8Cj+0C0Bi4IgcA4yhyADCOIgcA4yhyADCOIgcA45haaXh6iqC1c7XMV6xx9/jo7myTa2Mee3PApng0KPNd/e7BEme27pVryx6nWUxcPV/V9BRuL/4lA4BxFDkAGEeRA4BxFDkAGEeRA4BxTK00uERLh8w3bn9Q5t976S+cbPXm3XLtcJKJg7vJ8GRO5ht2ud+Vf+rqlGt/+lqrzM9E4jIfHfrSyQr5xj7V6W7EFTkAGEeRA4BxFDkAGEeRA8Bd8Pw3W8Y3gFA4KvP1Ow7J/Hsvf1fm+w89veSbmqU78Jf3OLbAFw7pa4pYxM3jEf0oeiSkXz3gcViC1+fPF0pOlkrrwzYWs0Vfo1Mfv6c1ItfG8uMy/8mrb8r8sxMfO9m1S5/Ltflc+uZvFH80rsgBwDiKHACMo8gBwDiKHACMo8gBwDge0b/dPCYolq1wD4SoePgRPbVy4NHHZX55qtAQ0yleh1ZsXK6nJfy5eZlPT006WXJ0Sq6dTenXyOf0o+uhkP7679+7w8ni7T1y7dDYoq/RqbMixmb172RZc7fMf/T978h8YtL9W0yNDcm1+eS1m79R/NG4IgcA4yhyADCOIgcA4yhyADCOIgcA45hauc0isSaZ923aJfPnnv0Tmd+Y1/uNFEuNsfdHxGNqZeD8aZm//sbbMp+amnayTEZPihSLej+UUEhPyqxYsVLmG7ZsdbJk6d44LCGbd/eZqZicm5V5cmLUyRZTyZq/L9wcV+QAYBxFDgDGUeQAYBxFDgDGUeQAYBxTK7dZe1evzA89+rDMY8vWyHxyWk9o1GDbF1/E47Qer4mGatbmC3rjl8uD38j8+sCpJZ804/f4QGu3HJD5E4+9KPNS3N1vJDujT1mqp2BAf57e7rjMx2eyMl+o4hSjzoTOf/6LYzK/PnzeyQr5e2PCp5FwRQ4AxlHkAGAcRQ4AxlHkAGAcRQ4AxjG1UkfBcNTJVvZulmsPPnRQ5hPzS58UqdbyNr0HyaoO931XnBqaW/IJNIWink5paWmVecCvP2d63j2Bpqx+oM/na+3UEz79O+6X+d4DD8p8JHXrE0G1EA7pqZVozj01qWJNk74um465v/O5tJ5kmZ8ckfmnn34m89TkVZnj9uKKHACMo8gBwDiKHACMo8gBwDhudtZRvKndyfr7t8u1iWX6kIOpmVu/2ZmI6kMoItlxmSfH9PpgQN+oVDc2Sx43JCMx/Xh5ItEsc3/AfS9BkVWsWr9D5s8+85TMZ4v6efRiqXDLNyRjYf0e59JVvHZQX2d9+vkZmX9yQt+QfOmvXnCybRs2ybX//qp+FP/a5XMy99ouAbcXV+QAYBxFDgDGUeQAYBxFDgDGUeQAYBxTK3XU1OYeULBzR79cO5/XUw4+360/Lt7dpCdf3nrzXZkfOLBf5sHONpkXfO6EisfQii8Q0tsCxBNNS55aae9eJ9cePKgfue/bslPml2twOMe6bj35ki+UbnlqxeN8D18qlZL5+a/Oyvyf/8Xd5uCRB/fItcdPnJT5zMQV7zeKO44rcgAwjiIHAOMocgAwjiIHAOMocgAwjqmVGvAH9P8P2zqWO1lvX59cu5DRG/1XKxZx30vy+pBc++VXF2W+c5fes6QloPcVqYY/oL9ysVhM5wl3f5fezbvk2iNH9J4q44v671MuL/133hzTU0XLm/QUyuUpj7GdKnh8rXyLi4syHx85L/OJaxecbHrKnWSpmLzurq3IZ9lTpZFxRQ4AxlHkAGAcRQ4AxlHkAGAcRQ4AxjG1UgOBYFjmnZ3uXitNrcvk2vnMrU85VLRE3f83n/hSnyiTmknKPJ/LybwGQyueoxjRqJ5a6Vq1xcke/9YhubalR08EjUxVt6eK+pzdCT3hcuzY5zLv3qT3q6mG1687m9V/n2JB53MzN5wsszBT5Yk/tfl+oj64IgcA4yhyADCOIgcA4yhyADCOm501EPS42blsWYeT+UOxut5KCvnzTjYwMCjXLsyOy7xQ0DcH/f76XTvE4vpgifWb3e0CHjv8mFw7ntKHOVSro9n9e144qw9cGBq+KvOumtzs1N+Kosffp1z2+PzilI/0vH5EHzZxRQ4AxlHkAGAcRQ4AxlHkAGAcRQ4AxjG1UgOBoD50IJFIOFnZr9fWjHhMeyrp9Sh+Rualkp6W8NdibMXjJUIhPfnzrUcPOFk57m59UJGdcSd2biYc1G8mUZ51sl+997Fcu2VT321/oL3kNZ3CY/T3LK7IAcA4ihwAjKPIAcA4ihwAjKPIAcA4plbqyC9OKKj3XIHab6NQLCx5D47605Mi3V3tMn/g4EEnuzFX3UERXrpb9df/+O+OOtnly3q/mi2b1vks8vv1NVzZ8zvBREwj44ocAIyjyAHAOIocAIyjyAHAOIocAIxjaqUGyiW990U2k3Uyv69U1/+n+kMRJ2tr0xMhwXBUv5NAtRMNS+e1Xcuhh/WJOvnwMicrLFa3p0o0rD9PMTUq89++/6GTTV6/KNeWSvq0onry+vt4TQQFxXeie819cu1s8prM03OcKNTIuCIHAOMocgAwjiIHAOMocgAwjiIHAOOYWqmBYlFPUczOzjiZ32OtzxetzXvxu6+zefMmuXbo8ojMQ+FQ3bZmaW1yT02qWLt9p8y/GErf8s/sbtbXK799R5/6M3ThtJNl5t2/ZUWxWJR5Dc5S8pU9XiUU0n+fUCQm85Xr73eytRt3yLVjV90poYrL54/LvOT5fcbtxBU5ABhHkQOAcRQ5ABhHkQOAcdzsrIFSQd/wSSYnnSy7mJJrg4EemRdL1d1hnMu4WwA8sH+vXHvy92dkHom4j3RXVPlWpLLHgQYjU/qwiEIVPzQW0a+dnroq86PHPpH59Jh7iEQ03qLfX0G/b38NDmLweoVoVN8Y71m7Xeb9/duc7JXvvCDXvv5fv5D5zKT+HU7d0Adu4PbiihwAjKPIAcA4ihwAjKPIAcA4ihwAjGNqpQZKJf2Y9nRyzMluXNcb93dsWCHz+Yx+bS+ZnDu10rtqvVy7b3e/zGMx/ah3qQbP6N+YcQ/bqFio8nMq3c36kfZ3f6Mfxb8ycFbmucyik4WjemuBXC5Xt0f0Pc4r8SUS+r1s69dTKz/6wV87WbBlpVz74p89I/PBgQGZL8xOOFk2PSfXon64IgcA4yhyADCOIgcA4yhyADCOIgcA45haqaP5mXEnO3fuvFz7TP8+/RqZ6n6mmisZn9drn3/+iMz9HjMXVxZvfWoltaj3JqlGPBKU+fyEPijjk09OyHxmfNjjJ7ifs+RxgEQmo6dw/D6PkZMqFD1eYusWPYX04EH9HVoIu/v4TE/qL1bvms0yf/KJx2U+ceOKk10b+EKuLXtMd+HWcUUOAMZR5ABgHEUOAMZR5ABgHEUOAMYxtVJH6fkpJzt79iu59k+fm5F5MNB6yycHpcX+KxXzsQ6Zr+vWe61cHmyMPTS6m3X+zrsfyXxkUO+pks+6e6p4KZX0KVDp9GKVUytL34UlX9R/4z3375H5N6NpmU/N6feujM7q9334ySdkfvqsO4WVSur9hFJT15f8PlAdrsgBwDiKHACMo8gBwDiKHACM42ZnHambacND38i15858KfPN+w7LfCK19BtYXiZT+lCEVLpQt4MlqpUQj+OnxvSj9SdOnJT57KT7GHm1vB7RX1hYkLm/5LUVQXjJPzOb1z/ziyG950Imf+vbAuQK+jWKrfrG+LefPORkg5cuyLULqUn92gX9PcTScUUOAMZR5ABgHEUOAMZR5ABgHEUOAMYxtVJHZTHlMXVjSK59/4OjMt+1Z6/Mw8Gmqh7rlu/PI8/WYPqhVrrE4/g//6X+XU1PTcg83qwnLuIt+nH5UCjqZInWLrk2X9SvUfZ4pL+aqRWvXRhqMZ3iJRzS13aJgH78/+z5i06WWZyVazlYon64IgcA4yhyADCOIgcA4yhyADCOIgcA45haaYDDJiq+/uqUzI99pA9LeOTp52U+knSnJW7/DinVS0TdPVUqYsWUkyWn9CEc6zb2y3xV7xaZBwIeExoJ92CNlT16amX/nu0y72jXB4KMZdw9WO7AFja+YEBP26zr0L+T9375K5kf/ehDJxsb1gd5lJhaqRuuyAHAOIocAIyjyAHAOIocAIyjyAHAOL+RoYa7XizRJvP+B74t83/8+7+Vectqd3JjvAanCd2pqZXNK9x9T3x5ve9HPqvzQkGf1uP3mFqJRN2pFX84LtfOZvT0x9isPvUmk7v9+9gExIRKX6fe8+XLEx/I/N9ee0Pml864UyuZBb3XCuqHK3IAMI4iBwDjKHIAMI4iBwDjKHIAMI6plYahpx+WLe+T+b5Hjsj8H/7uB06Wi6+Sa5NzjT/NUs0+IV65x3CK5x4nRXE0j8pu9hp3gtfn7+tyJ1S+PnVcrv3paz+T+YU/6GmW+Zmxqt4j6oMrcgAwjiIHAOMocgAwjiIHAOO42dng/AH96PryXn2gwf6HnnCyH//wJbm2mFhd1ePlaOybmht79GP3fzjhHk7yHz97W669dOZjmc8mr/ka/m7vPYwrcgAwjiIHAOMocgAwjiIHAOMocgAwLnSn3wBurlwqynx85LzMT4XcyYU3mpvk2r/5sT6cAo3Nr4dWfPPT4zL/77fedbJLZ47KtSmmU0ziihwAjKPIAcA4ihwAjKPIAcA4ihwAjGNqxahSUR8KsTA74WRtba1y7WLB6//jelKmGtGwfu18UU8/lDwObrAqFNSjJfGIu3fOQkb/vksekyIFj9+hP9Es87YWd2opu5iSa8tMp5jEFTkAGEeRA4BxFDkAGEeRA4BxFDkAGMfUilF+jw032jrdU3927Ngm185na/NeElF3EmNLl8d0ise1Q7Yckfl81n2ddLZY1USM1ySG1+9QTZyoz1jRGvN4jeKizH1l9/SlYX9cLk0tFnzVyPtjMt++fauTfXasR67NLM5W9TPRGLgiBwDjKHIAMI4iBwDjKHIAMI4iBwDjmFoxKhxNyLxrxVon61u7Uq71N7unCVVk86Wq9vjoanLz115/U64dHZuU+YZ17rRNRV/vKifr7uqUa9ua9O8kGNRf81JRf87FOXfiZHjc3cOmYmBwROYXB6/IfNWKbid7/i+/K9emPAZfYhF9/dXh8ffctKHXydq718i102ODMi95nFSFxsAVOQAYR5EDgHEUOQAYR5EDgHHc7DQqENQ3thYW3Dtk//qTN+TaI08fkvmO+/fo1y7pR8knr3ztZEePHZdrx6/pm2mnmttlHo23OFk4oh9FD4X01zkYCFR3cEPePbQjl8vItdkFfUBDemFK5hMbtzvZs88l5dqNy90bvRXhwozMP3n/dzL/nw9PLHnbgoDXjWFudjY0rsgBwDiKHACMo8gBwDiKHACMo8gBwDimVozKLOgDAAbPfuBkMxP6cfGBwSGZb9t6UuZPH35I5kePf+FkVwdOy7XJ0Usy9wf0wQ2hkHvgRCCkJ3YCHq/h9+vrlbLP4yCKojuhUSy4B0JUFAr6dA7PqZCA+0/u0+PuVElFZ6ee5HnvfT0RNDQ0IPPJ6xecbHZSby1QyNfotBHcVlyRA4BxFDkAGEeRA4BxFDkAGEeRA4Bx/v+7eY+7mt9f+TO7ovFWmXes3CjzzhXrZZ7LLDjZwBl3eqai4LFnyb0i0drlZJt2HZZr8x6/q8nrevJnZmJYv07W44QK3DW4IgcA4yhyADCOIgcA4yhyADCOIgcA45hawZKnXGJN7Uve42QhNVnz93U3UL+rlg59ElB6fnrJU0L/j3/K9yquyAHAOIocAIyjyAHAOIocAIzjZicAGMcVOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQAYR5EDgHEUOQD4bPtfFbJ6pLgpHyQAAAAASUVORK5CYII=\" id=\"image42b125407b\" transform=\"scale(1 -1) translate(0 -266.4)\" x=\"7.2\" y=\"-21.655125\" width=\"266.4\" height=\"266.4\"/>\n",
       "   </g>\n",
       "   <g id=\"text_1\">\n",
       "    <!-- Loaded UNC Logo (Original) -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(64.221 15.943125) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-4c\" d=\"M 469 0 \n",
       "L 469 4581 \n",
       "L 1075 4581 \n",
       "L 1075 541 \n",
       "L 3331 541 \n",
       "L 3331 0 \n",
       "L 469 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-6f\" d=\"M 213 1659 \n",
       "Q 213 2581 725 3025 \n",
       "Q 1153 3394 1769 3394 \n",
       "Q 2453 3394 2887 2945 \n",
       "Q 3322 2497 3322 1706 \n",
       "Q 3322 1066 3130 698 \n",
       "Q 2938 331 2570 128 \n",
       "Q 2203 -75 1769 -75 \n",
       "Q 1072 -75 642 372 \n",
       "Q 213 819 213 1659 \n",
       "z\n",
       "M 791 1659 \n",
       "Q 791 1022 1069 705 \n",
       "Q 1347 388 1769 388 \n",
       "Q 2188 388 2466 706 \n",
       "Q 2744 1025 2744 1678 \n",
       "Q 2744 2294 2464 2611 \n",
       "Q 2184 2928 1769 2928 \n",
       "Q 1347 2928 1069 2612 \n",
       "Q 791 2297 791 1659 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-61\" d=\"M 2588 409 \n",
       "Q 2275 144 1986 34 \n",
       "Q 1697 -75 1366 -75 \n",
       "Q 819 -75 525 192 \n",
       "Q 231 459 231 875 \n",
       "Q 231 1119 342 1320 \n",
       "Q 453 1522 633 1644 \n",
       "Q 813 1766 1038 1828 \n",
       "Q 1203 1872 1538 1913 \n",
       "Q 2219 1994 2541 2106 \n",
       "Q 2544 2222 2544 2253 \n",
       "Q 2544 2597 2384 2738 \n",
       "Q 2169 2928 1744 2928 \n",
       "Q 1347 2928 1158 2789 \n",
       "Q 969 2650 878 2297 \n",
       "L 328 2372 \n",
       "Q 403 2725 575 2942 \n",
       "Q 747 3159 1072 3276 \n",
       "Q 1397 3394 1825 3394 \n",
       "Q 2250 3394 2515 3294 \n",
       "Q 2781 3194 2906 3042 \n",
       "Q 3031 2891 3081 2659 \n",
       "Q 3109 2516 3109 2141 \n",
       "L 3109 1391 \n",
       "Q 3109 606 3145 398 \n",
       "Q 3181 191 3288 0 \n",
       "L 2700 0 \n",
       "Q 2613 175 2588 409 \n",
       "z\n",
       "M 2541 1666 \n",
       "Q 2234 1541 1622 1453 \n",
       "Q 1275 1403 1131 1340 \n",
       "Q 988 1278 909 1158 \n",
       "Q 831 1038 831 891 \n",
       "Q 831 666 1001 516 \n",
       "Q 1172 366 1500 366 \n",
       "Q 1825 366 2078 508 \n",
       "Q 2331 650 2450 897 \n",
       "Q 2541 1088 2541 1459 \n",
       "L 2541 1666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-64\" d=\"M 2575 0 \n",
       "L 2575 419 \n",
       "Q 2259 -75 1647 -75 \n",
       "Q 1250 -75 917 144 \n",
       "Q 584 363 401 755 \n",
       "Q 219 1147 219 1656 \n",
       "Q 219 2153 384 2558 \n",
       "Q 550 2963 881 3178 \n",
       "Q 1213 3394 1622 3394 \n",
       "Q 1922 3394 2156 3267 \n",
       "Q 2391 3141 2538 2938 \n",
       "L 2538 4581 \n",
       "L 3097 4581 \n",
       "L 3097 0 \n",
       "L 2575 0 \n",
       "z\n",
       "M 797 1656 \n",
       "Q 797 1019 1065 703 \n",
       "Q 1334 388 1700 388 \n",
       "Q 2069 388 2326 689 \n",
       "Q 2584 991 2584 1609 \n",
       "Q 2584 2291 2321 2609 \n",
       "Q 2059 2928 1675 2928 \n",
       "Q 1300 2928 1048 2622 \n",
       "Q 797 2316 797 1656 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-65\" d=\"M 2694 1069 \n",
       "L 3275 997 \n",
       "Q 3138 488 2766 206 \n",
       "Q 2394 -75 1816 -75 \n",
       "Q 1088 -75 661 373 \n",
       "Q 234 822 234 1631 \n",
       "Q 234 2469 665 2931 \n",
       "Q 1097 3394 1784 3394 \n",
       "Q 2450 3394 2872 2941 \n",
       "Q 3294 2488 3294 1666 \n",
       "Q 3294 1616 3291 1516 \n",
       "L 816 1516 \n",
       "Q 847 969 1125 678 \n",
       "Q 1403 388 1819 388 \n",
       "Q 2128 388 2347 550 \n",
       "Q 2566 713 2694 1069 \n",
       "z\n",
       "M 847 1978 \n",
       "L 2700 1978 \n",
       "Q 2663 2397 2488 2606 \n",
       "Q 2219 2931 1791 2931 \n",
       "Q 1403 2931 1139 2672 \n",
       "Q 875 2413 847 1978 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-20\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-55\" d=\"M 3500 4581 \n",
       "L 4106 4581 \n",
       "L 4106 1934 \n",
       "Q 4106 1244 3950 837 \n",
       "Q 3794 431 3386 176 \n",
       "Q 2978 -78 2316 -78 \n",
       "Q 1672 -78 1262 144 \n",
       "Q 853 366 678 786 \n",
       "Q 503 1206 503 1934 \n",
       "L 503 4581 \n",
       "L 1109 4581 \n",
       "L 1109 1938 \n",
       "Q 1109 1341 1220 1058 \n",
       "Q 1331 775 1601 622 \n",
       "Q 1872 469 2263 469 \n",
       "Q 2931 469 3215 772 \n",
       "Q 3500 1075 3500 1938 \n",
       "L 3500 4581 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-4e\" d=\"M 488 0 \n",
       "L 488 4581 \n",
       "L 1109 4581 \n",
       "L 3516 984 \n",
       "L 3516 4581 \n",
       "L 4097 4581 \n",
       "L 4097 0 \n",
       "L 3475 0 \n",
       "L 1069 3600 \n",
       "L 1069 0 \n",
       "L 488 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-43\" d=\"M 3763 1606 \n",
       "L 4369 1453 \n",
       "Q 4178 706 3683 314 \n",
       "Q 3188 -78 2472 -78 \n",
       "Q 1731 -78 1267 223 \n",
       "Q 803 525 561 1097 \n",
       "Q 319 1669 319 2325 \n",
       "Q 319 3041 592 3573 \n",
       "Q 866 4106 1370 4382 \n",
       "Q 1875 4659 2481 4659 \n",
       "Q 3169 4659 3637 4309 \n",
       "Q 4106 3959 4291 3325 \n",
       "L 3694 3184 \n",
       "Q 3534 3684 3231 3912 \n",
       "Q 2928 4141 2469 4141 \n",
       "Q 1941 4141 1586 3887 \n",
       "Q 1231 3634 1087 3207 \n",
       "Q 944 2781 944 2328 \n",
       "Q 944 1744 1114 1308 \n",
       "Q 1284 872 1643 656 \n",
       "Q 2003 441 2422 441 \n",
       "Q 2931 441 3284 734 \n",
       "Q 3638 1028 3763 1606 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-67\" d=\"M 319 -275 \n",
       "L 866 -356 \n",
       "Q 900 -609 1056 -725 \n",
       "Q 1266 -881 1628 -881 \n",
       "Q 2019 -881 2231 -725 \n",
       "Q 2444 -569 2519 -288 \n",
       "Q 2563 -116 2559 434 \n",
       "Q 2191 0 1641 0 \n",
       "Q 956 0 581 494 \n",
       "Q 206 988 206 1678 \n",
       "Q 206 2153 378 2554 \n",
       "Q 550 2956 876 3175 \n",
       "Q 1203 3394 1644 3394 \n",
       "Q 2231 3394 2613 2919 \n",
       "L 2613 3319 \n",
       "L 3131 3319 \n",
       "L 3131 450 \n",
       "Q 3131 -325 2973 -648 \n",
       "Q 2816 -972 2473 -1159 \n",
       "Q 2131 -1347 1631 -1347 \n",
       "Q 1038 -1347 672 -1080 \n",
       "Q 306 -813 319 -275 \n",
       "z\n",
       "M 784 1719 \n",
       "Q 784 1066 1043 766 \n",
       "Q 1303 466 1694 466 \n",
       "Q 2081 466 2343 764 \n",
       "Q 2606 1063 2606 1700 \n",
       "Q 2606 2309 2336 2618 \n",
       "Q 2066 2928 1684 2928 \n",
       "Q 1309 2928 1046 2623 \n",
       "Q 784 2319 784 1719 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-28\" d=\"M 1497 -1347 \n",
       "Q 1031 -759 709 28 \n",
       "Q 388 816 388 1659 \n",
       "Q 388 2403 628 3084 \n",
       "Q 909 3875 1497 4659 \n",
       "L 1900 4659 \n",
       "Q 1522 4009 1400 3731 \n",
       "Q 1209 3300 1100 2831 \n",
       "Q 966 2247 966 1656 \n",
       "Q 966 153 1900 -1347 \n",
       "L 1497 -1347 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-4f\" d=\"M 309 2231 \n",
       "Q 309 3372 921 4017 \n",
       "Q 1534 4663 2503 4663 \n",
       "Q 3138 4663 3647 4359 \n",
       "Q 4156 4056 4423 3514 \n",
       "Q 4691 2972 4691 2284 \n",
       "Q 4691 1588 4409 1038 \n",
       "Q 4128 488 3612 205 \n",
       "Q 3097 -78 2500 -78 \n",
       "Q 1853 -78 1343 234 \n",
       "Q 834 547 571 1087 \n",
       "Q 309 1628 309 2231 \n",
       "z\n",
       "M 934 2222 \n",
       "Q 934 1394 1379 917 \n",
       "Q 1825 441 2497 441 \n",
       "Q 3181 441 3623 922 \n",
       "Q 4066 1403 4066 2288 \n",
       "Q 4066 2847 3877 3264 \n",
       "Q 3688 3681 3323 3911 \n",
       "Q 2959 4141 2506 4141 \n",
       "Q 1863 4141 1398 3698 \n",
       "Q 934 3256 934 2222 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-72\" d=\"M 416 0 \n",
       "L 416 3319 \n",
       "L 922 3319 \n",
       "L 922 2816 \n",
       "Q 1116 3169 1280 3281 \n",
       "Q 1444 3394 1641 3394 \n",
       "Q 1925 3394 2219 3213 \n",
       "L 2025 2691 \n",
       "Q 1819 2813 1613 2813 \n",
       "Q 1428 2813 1281 2702 \n",
       "Q 1134 2591 1072 2394 \n",
       "Q 978 2094 978 1738 \n",
       "L 978 0 \n",
       "L 416 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-69\" d=\"M 425 3934 \n",
       "L 425 4581 \n",
       "L 988 4581 \n",
       "L 988 3934 \n",
       "L 425 3934 \n",
       "z\n",
       "M 425 0 \n",
       "L 425 3319 \n",
       "L 988 3319 \n",
       "L 988 0 \n",
       "L 425 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-6e\" d=\"M 422 0 \n",
       "L 422 3319 \n",
       "L 928 3319 \n",
       "L 928 2847 \n",
       "Q 1294 3394 1984 3394 \n",
       "Q 2284 3394 2536 3286 \n",
       "Q 2788 3178 2913 3003 \n",
       "Q 3038 2828 3088 2588 \n",
       "Q 3119 2431 3119 2041 \n",
       "L 3119 0 \n",
       "L 2556 0 \n",
       "L 2556 2019 \n",
       "Q 2556 2363 2490 2533 \n",
       "Q 2425 2703 2258 2804 \n",
       "Q 2091 2906 1866 2906 \n",
       "Q 1506 2906 1245 2678 \n",
       "Q 984 2450 984 1813 \n",
       "L 984 0 \n",
       "L 422 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-6c\" d=\"M 409 0 \n",
       "L 409 4581 \n",
       "L 972 4581 \n",
       "L 972 0 \n",
       "L 409 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-29\" d=\"M 791 -1347 \n",
       "L 388 -1347 \n",
       "Q 1322 153 1322 1656 \n",
       "Q 1322 2244 1188 2822 \n",
       "Q 1081 3291 891 3722 \n",
       "Q 769 4003 388 4659 \n",
       "L 791 4659 \n",
       "Q 1378 3875 1659 3084 \n",
       "Q 1900 2403 1900 1659 \n",
       "Q 1900 816 1576 28 \n",
       "Q 1253 -759 791 -1347 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-4c\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" transform=\"translate(55.615234 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-61\" transform=\"translate(111.230469 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-64\" transform=\"translate(166.845703 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(222.460938 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-64\" transform=\"translate(278.076172 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" transform=\"translate(333.691406 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-55\" transform=\"translate(361.474609 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-4e\" transform=\"translate(433.691406 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-43\" transform=\"translate(505.908203 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" transform=\"translate(578.125 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-4c\" transform=\"translate(605.908203 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" transform=\"translate(661.523438 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-67\" transform=\"translate(717.138672 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" transform=\"translate(772.753906 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" transform=\"translate(828.369141 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-28\" transform=\"translate(856.152344 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-4f\" transform=\"translate(889.453125 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" transform=\"translate(967.236328 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(1000.537109 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-67\" transform=\"translate(1022.753906 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(1078.369141 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" transform=\"translate(1100.585938 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-61\" transform=\"translate(1156.201172 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6c\" transform=\"translate(1211.816406 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-29\" transform=\"translate(1234.033203 0)\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p0c9b9db7b6\">\n",
       "   <rect x=\"7.2\" y=\"21.943125\" width=\"266.112\" height=\"266.112\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PATCH_SIZE = 64 # We'll create a 64x64 patch\n",
    "\n",
    "# Load the logo\n",
    "assert os.path.isfile(LOGO_PATH), f\"File not found at {LOGO_PATH}. Please add ung_logo.png to data/\"\n",
    "logo_img = Image.open(LOGO_PATH).convert(\"RGB\")\n",
    "\n",
    "# Define transforms to make it a 64x64 tensor\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((PATCH_SIZE, PATCH_SIZE)),\n",
    "    transforms.ToTensor() # This scales pixels to [0, 1]\n",
    "])\n",
    "\n",
    "# Apply transforms\n",
    "logo_tensor_0_1 = data_transforms(logo_img) # Shape [3, 64, 64], range [0, 1]\n",
    "\n",
    "# --- Inverse of patch_forward ---\n",
    "# We need to convert our [0, 1] logo tensor into the\n",
    "# \"unbound\" space that tanh() will map *back* to our logo.\n",
    "# 1. [0, 1] -> [-1, 1]\n",
    "logo_tensor_m1_1 = (logo_tensor_0_1 * 2.0) - 1.0\n",
    "# 2. Clamp to avoid inf/-inf from arctanh\n",
    "logo_tensor_m1_1_clamped = torch.clamp(logo_tensor_m1_1, min=-1.0+1e-7, max=1.0-1e-7)\n",
    "# 3. Apply arctanh (inverse of tanh)\n",
    "patch_init_unbound = torch.arctanh(logo_tensor_m1_1_clamped)\n",
    "patch_init_unbound = patch_init_unbound.to(device)\n",
    "\n",
    "print(f\"Successfully loaded and processed logo into a {patch_init_unbound.shape} tensor.\")\n",
    "\n",
    "# Let's visualize the logo to make sure it loaded correctly\n",
    "plt.imshow(logo_tensor_0_1.permute(1, 2, 0).numpy())\n",
    "plt.title(\"Loaded UNC Logo (Original)\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d684c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_patch_attack(model, target_class, patch_init_tensor, num_epochs=10):\n",
    "    # Create the training/validation split\n",
    "    train_set, val_set = torch.utils.data.random_split(dataset, [4500, 500])\n",
    "    \n",
    "    # --- THIS IS FIX 3 (for Windows) ---\n",
    "    train_loader = data.DataLoader(train_set, batch_size=32, shuffle=True, drop_last=True, num_workers=0)\n",
    "    val_loader = data.DataLoader(val_set, batch_size=32, shuffle=False, drop_last=False, num_workers=0)\n",
    "\n",
    "    # *** THIS IS THE KEY CHANGE ***\n",
    "    # Initialize the patch parameter with our logo tensor\n",
    "    patch = nn.Parameter(patch_init_tensor.clone(), requires_grad=True)\n",
    "\n",
    "    # Use Adam optimizer, which works well for fine-tuning\n",
    "    optimizer = torch.optim.Adam([patch], lr=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n",
    "    loss_module = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(f\"Starting attack. Tuning patch to target class '{label_names[target_class]}'\")\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        t = tqdm(train_loader, leave=False)\n",
    "        model.train() # Not strictly necessary, but good practice\n",
    "        for img, _ in t:\n",
    "            # Place the patch on the batch of images\n",
    "            img = place_patch(img.clone(), patch)\n",
    "            img = img.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            pred = model(img)\n",
    "            # Create a tensor of our target class\n",
    "            labels = torch.zeros(img.shape[0], device=pred.device, dtype=torch.long).fill_(target_class)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = loss_module(pred, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            t.set_description(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():4.2f}\")\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        scheduler.step(avg_train_loss)\n",
    "        print(f\"Epoch {epoch+1} finished. Avg Loss: {avg_train_loss:4.2f}\")\n",
    "\n",
    "    # Final validation\n",
    "    print(\"Training finished. Running final validation...\")\n",
    "    acc, top5 = eval_patch(model, patch, val_loader, target_class)\n",
    "\n",
    "    return patch.data, {\"acc\": acc.item(), \"top5\": top5.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1fbf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting attack... Target: 'ashcan' (412)\n",
      "Starting attack. Tuning patch to target class 'ashcan'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3367170bd2eb40c5974341669bb3268b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 finished. Avg Loss: 10.61\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d19ff8f8e84df1b8b2185db71feb6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 finished. Avg Loss: 9.48\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b459deeb0e9445f1b5e17f39af3e4f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# target_class_idx and target_class_name were defined in Cell 5\n",
    "print(f\"Starting attack... Target: '{target_class_name}' ({target_class_idx})\")\n",
    "\n",
    "# Run the attack\n",
    "custom_patch_tensor, val_results = custom_patch_attack(\n",
    "    pretrained_model, \n",
    "    target_class=target_class_idx, \n",
    "    patch_init_tensor=patch_init_unbound,\n",
    "    num_epochs=10 # Feel free to increase this if needed\n",
    ")\n",
    "                               \n",
    "print(f\"Validation results for '{target_class_name}':\")\n",
    "print(f\"  Top-1 Fooling Accuracy: {val_results['acc']*100.0:4.2f}%\")\n",
    "print(f\"  Top-5 Fooling Accuracy: {val_results['top5']*100.0:4.2f}%\")\n",
    "\n",
    "# Save the final patch tensor\n",
    "patch_filename = os.path.join(CUSTOM_PATCH_PATH, f\"unc_to_{target_class_name.replace(' ', '_')}_patch.pt\")\n",
    "torch.save(custom_patch_tensor, patch_filename)\n",
    "print(f\"Patch tensor saved to {patch_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f136365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
